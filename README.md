# My-Portfolio

## [Project: From Data to Insight - Eine Case Study mit der SAP Analytics Cloud und KPMG (02.06.2025 - 14.07.2025)](https://github.com/DucTung269/KPMG-Casestudy)

### Case Study: E-Car Sales Data Processing and Visualization

This case study was completed as part of one of my master’s modules, where I had the opportunity to work on a real project in collaboration with **KPMG**.  
The focus of the project was on **data processing, presentation, and visualization** of E-Car sales data according to specific customer requirements.  

Together with my group, we prepared a final **pitch** to present the results and deliver **consulting solutions** for E-Car sales.  
The processed data was presented in the form of an **interactive dashboard** using **SAP Analytics Cloud (SAC)**.  

---

### Project Details

- **[Data Source](https://github.com/DucTung269/KPMG-Casestudy/tree/main/Raw%20Dataset)**: Provided by KPMG, containing E-Car sales information  
- **Tools Used**:
  - Microsoft Excel
  - Excel Power Query
  -  SAP Analytics Cloud (SAC)
  -  SAP Functions  
- **Tasks Performed**:  
  - Cleaning and transforming data using Excel and Power Query  
  - Creating dashboards in SAC for visualization and reporting  
  - Pitching results and consulting recommendations to stakeholders

---
 
### Results Overview

![Summery Dashboard](https://github.com/DucTung269/My-Portfolio/blob/main/Images/KPMG%20Summery%201.png?raw=true)

This dashboard summarizes Fiara AG’s business results for 2022.  It highlights the **top 10 customers by order value**, with Zoe Ross as the largest contributor.  In total, the company recorded **1,497 orders** with a combined value of **€1.9 billion**.  The **geographic distribution** shows a strong concentration in **Europe**, with additional activity in North America and Asia.  A **time series analysis** of the contribution margin indicates significant fluctuations, with peaks in **March, July, and November**, reflecting seasonal or project-driven performance trends.  


![Auftragswertübersicht](https://github.com/DucTung269/My-Portfolio/blob/main/Images/KPMG%20Auftragswert%C3%BCbersicht%202.png?raw=true)


This dashboard adds further detail by showing the **number of cars sold (45,319)** and highlighting financial aspects such as **delivery conditions (€26.7M)** and **price conditions (€30.6M)**.  It also provides a **month-by-month breakdown of order values**, with the strongest performance in **October (€219M)** and the weakest in **December (€92M)**.  Additionally, a detailed **order list with customer IDs, names, and tax information** offers transparency at the transaction level.  


![Kundenübersicht](https://github.com/DucTung269/My-Portfolio/blob/main/Images/KPMG%20Kunden%C3%BCbersicht%203%20.png?raw=true)


This dashboard provides a **customer-centric view** of Fiara AG’s business in 2022.  It shows a total of **999 active customers** contributing to an overall order value of **€1.9 billion**.  The analysis includes:   **Customer segmentation** by country, **Customer type** (e.g., B2B),  **System landscape** (Microsoft, SAP).A **geographic map** highlights strong activity across European markets.  Additionally, detailed **customer transactions** are displayed, covering **product types and system affiliations**.  On the right, the **top 10 customers by order value** are listed, with **Zoe Ross** remaining the leading client.  


![Produktübersicht](https://github.com/DucTung269/My-Portfolio/blob/main/Images/KPMG%20Produkt%C3%BCbersicht%204.png?raw=true)


This dashboard focuses on product performance by comparing order values, variable costs, and contribution margins across different vehicle categories. Commercial vehicles and station wagons stand out with the highest sales and profitability, while compact and mini cars contribute significantly less in both revenue and margins. 


![Marktübersicht](https://github.com/DucTung269/My-Portfolio/blob/main/Images/KPMG%20Markt%C3%BCbersicht%205.png?raw=true)



This dashboard provides insights into Fiara AG’s performance across **10 customer countries**.   **France** leads with the highest order value (€288M) and cars sold (6,074), followed by **Italy** and the **USA**. At the lower end, the **Czech Republic** records the weakest performance with €49M in orders and only 1,238 cars sold.  

---
 
### Conclusion

The analysis highlights Fiara AG’s strong focus on **10 core markets**, with **Europe** as the primary sales region.  **October** proved to be the most successful month of the year, supported by high sales volumes of **station wagons and commercial vehicles**, which dominate the product portfolio.  In total, more than **45,000 vehicles** were sold, generating an **order value of over €1.9 billion** from nearly **1,500 completed contracts**.  

From a market perspective:  
- **France** represents the strongest sales country for station wagons.  
- **Italy** leads in commercial vehicles.  
- **Czech Republic** shows significant market weakness, making expansion urgently necessary.  
- In **China**, brand presence must be strengthened, with clear demand for **cabrios and minivans**.  

Overall, Fiara AG demonstrates **solid performance in Central and Southern Europe**, but further strategic efforts are required to improve competitiveness in **Eastern Europe** and fully leverage opportunities in **Asia**.  


---

## [Projekt: Roessler Atraktor (25.05.2022 – 23.06.2022)](https://github.com/DucTung269/Roessler-Atraktor)

Im Rahmen eines Bachelor-Moduls entwickelte ich ein mathematisches Modell in **Python**, das den **Rössler-Attraktor** beschreibt. 

Der Rössler-Attraktor stellt ein klassisches Beispiel für ein **chaotisches dynamisches System** dar, das durch das sogenannte Rössler-System definiert ist. Dieses **nichtlineare System** basiert auf drei gekoppelten Differentialgleichungen, die die zeitabhängige Entwicklung der Variablen *(x, y, z)* modellieren. Charakteristisch für den Attraktor ist sein chaotisches Verhalten: Bereits minimale Änderungen in den Anfangsbedingungen oder Parametern führen zu signifikanten und nicht vorhersagbaren Abweichungen im Systemverlauf. In der **Chaosforschung** dient die Simulation des Rössler-Attraktors häufig als Untersuchungsgrundlage für nichtlineare Dynamik und deterministisches Chaos. Für die numerische Integration der Differentialgleichungen und die Visualisierung der Ergebnisse nutzte ich **Python** als Programmiersprache.

---
### Projektdetails
- **Modell**: Mathematisches Modell des Rössler-Attraktors  
- **Numerische Verfahren**: Runge-Kutta-Methoden (4. und 8. Ordnung)  
- **Verwendete Tools und Bibliotheken**: Implementierung in **Python**  
  - *NumPy*  
  - *SciPy.integrate*  
  - *Matplotlib.pyplot*  
  - *mpl_toolkits.mplot3d*  
  - *Matplotlib.animation*

---

### Ergebnisseübersicht  

- **Code**: Der Python-Code zur Implementierung des Rössler-Attraktors, einschließlich der numerischen Lösung mit dem Runge-Kutta-Verfahren sowie der Animation, befindet sich im Jupyter Notebook *Roessler Atraktor.ipynb* in [meinem Repository](https://github.com/DucTung269/Roessler-Atraktor).  

- **Animation**: Die Dynamik des Rössler-Attraktors wird in der folgenden Abbildung als Animation dargestellt.  
![Rössler Attraktor Animation](https://github.com/DucTung269/Roessler-Atraktor/blob/main/roessler_attraktor.gif?raw=true)

#### Variation des Rössler-Attraktors  

- **Startwerte**: (1.0, 1.0, 1.0) mit Variation des Parameters *c* zwischen 2 und 7:  

  - Für *c = 2*  
    ![c = 2](https://github.com/DucTung269/Roessler-Atraktor/blob/main/image/c%20=%202.jpg?raw=true)  

  - Für *c = 7*  
    ![c = 7](https://github.com/DucTung269/Roessler-Atraktor/blob/main/image/c%20=%207.jpg?raw=true)  

---

- **Startwerte**: (1.01, 1.0, 1.0) mit Variation des Parameters *c*:  

  - Für *c = 3.3*  
    ![c = 3.3](https://github.com/DucTung269/Roessler-Atraktor/blob/main/image/c%20=%203.3.jpg?raw=true)  

  - Für *c = 6.6*  
    ![c = 6.6](https://github.com/DucTung269/Roessler-Atraktor/blob/main/image/c%20=%206.3.jpg?raw=true)

### Fazit  

Der **Rössler-Attraktor** ist ein typischer *seltsamer Attraktor* mit starker Abhängigkeit von den Anfangsbedingungen. Für seine numerische Lösung wurden das **Runge-Kutta-Verfahren 4. Ordnung** und das **Runge-Kutta-Verfahren 8. Ordnung** eingesetzt, wobei auch andere Verfahren wie das **Euler-Verfahren** möglich wären. Die Simulationen zeigen, dass bereits kleine Änderungen der Anfangswerte oder Parameter zu deutlichen Abweichungen im Verhalten der Trajektorien führen. Besonders stabil tritt die charakteristische **Rössler-Form** bei den Parametern *(a = 0.2, b = 0.2, c = 5.7)* auf, während Abweichungen davon eine andere Dynamik erzeugen.  

---
## [Projekt: Deep-Learning-Predicting-Creditworthiness(01.11.2024-14.02.2025)](https://github.com/DucTung269/Deep-Learning-Predicting-Creditworthiness)

Im Rahmen meines Masterseminars wurde ein Projekt zur **Vorhersage der Kreditwürdigkeit** entwickelt. Ziel war es, mithilfe moderner Machine-Learning-Methoden wie **Künstlichen Neuronalen Netzen (Artificial Neural Networks, ANN)** und dem **XGBoost-Algorithmus** präzise Vorhersagen über die Bonität von Kreditnehmern zu treffen. Beide Modelle wurden in **Python** implementiert und auf reale Datensätze angewendet.  

Ein zentraler Aspekt des Projekts war die **Erklärbarkeit der Modelle**, da die Nachvollziehbarkeit von algorithmischen Entscheidungen im Finanzkontext von großer Bedeutung ist. Zur Interpretation der Ergebnisse kamen **SHAP** (*Shapley Additive Explanations*) und **ALE** (*Accumulated Local Effects*) zum Einsatz. Diese Methoden ermöglichen eine detaillierte Analyse der Modellentscheidungen und schaffen Transparenz hinsichtlich der Einflussfaktoren auf die Kreditwürdigkeit.  

Durch den Vergleich der beiden Erklärbarkeitsansätze wurde untersucht, welche Variablen die Kreditwürdigkeit besonders stark beeinflussen und inwiefern sich die zugrunde liegenden Modelle interpretierbar und vertrauenswürdig gestalten lassen.  

---
### Projektdetails  

- **Datenquelle**: [German Credit Data](https://www.kaggle.com/datasets/mpwolke/cusersmarildownloadsgermancsv)  
- **Modelle**: Neuronales Netz (Artificial Neural Network) und XGBoost  
- **Verwendete Tools und Bibliotheken**: Implementierung in **Python**  
  - *NumPy*  
  - *Pandas*  
  - *sklearn.preprocessing*: *StandardScaler*  
  - *sklearn.model_selection*: *train_test_split*  
  - *sklearn.metrics*: *accuracy_score*, *f1_score*  
  - *matplotlib.pyplot*  
  - *torch*  
  - *shap*  
  - *alibi.explainers*: *ALE*  
  - *XGBoost*  

---
### Ergebnisseübetsicht
- **Code**: Der Python-Code zur Implementierung der Datenvorverarbeitung, des **Artificial-Neural-Network-Modells** sowie der Ergebnisinterpretation befindet sich im Jupyter Notebook *Predicting Creditworthiness.ipynb* in [meinem Repository](https://github.com/DucTung269/Deep-Learning-Predicting-Creditworthiness).  
- **Dataset and Data Preprocessing**: Der Datensatz umfasst **1000 Beobachtungen** mit **21 Variablen**. Die meisten dieser Eingangsvariablen sind kategorial und repräsentieren unterschiedliche Zustände oder Ausprägungen einer bestimmten Eigenschaft. Der Datensatz enthält grundlegende Informationen über Kreditnehmer, wie beispielsweise **Kreditbetrag**, **Familienstand**, **Alter**, **Beschäftigungsstatus**, **Kreditzweck** sowie die Information, ob der Kreditnehmer **im Ausland beschäftigt** ist.  

  Die Zielvariable **Creditability** dient der Klassifikation der Kreditwürdigkeit einer Person. Ein Wert von **1** steht für *kreditwürdig* (kein Zahlungsausfall), während ein Wert von **0** *nicht kreditwürdig* bedeutet (Zahlungsausfall).  

![ ](https://github.com/DucTung269/Deep-Learning-Predicting-Creditworthiness/blob/main/images/imbalance%20dataset.jpg?raw=true)

- Wie in der Abbildung dargestellt, ist die Anzahl der **not default** (kein Zahlungsausfall) deutlich höher als die der **default** (Zahlungsausfall) (700 gegenüber 300). Um dieses **Klassenungleichgewicht** zu adressieren, wurde ein entsprechender Schritt der **Datenvorverarbeitung** implementiert.  

- Zur Korrektur des Ungleichgewichts wurde die Methode der **Class Weights** angewendet. Dabei erhalten Beobachtungen der Mehrheitsklasse ein geringeres Gewicht, während Beobachtungen der Minderheitsklasse stärker gewichtet werden. Auf diese Weise wird das Modell dazu veranlasst, der Minderheitsklasse während der Berechnung der Verlustfunktion mehr Aufmerksamkeit zu schenken, was zu einer ausgewogeneren Modellleistung führt.  

![classweight](https://github.com/DucTung269/Deep-Learning-Predicting-Creditworthiness/blob/main/images/classweight.jpg?raw=true)

- Darüber hinaus kam während der Datenvorverarbeitung der **StandardScaler()** zum Einsatz. Dieses Verfahren standardisiert die Eingangsvariablen, indem es sie so transformiert, dass sie einen Mittelwert von 0 und eine Standardabweichung von 1 aufweisen. Durch diese **Normalisierung** befinden sich alle Merkmale auf einer vergleichbaren Skala, was **die Trainingsstabilität verbessert** und **eine Verzerrung zugunsten großskaliger Variablen verhindert**. Somit trägt die Standardisierung wesentlich dazu bei, dass alle Merkmale einen gleichberechtigten Einfluss auf die Modellvorhersage haben.  

#### Artificial Neural Network
![ANN Code](https://github.com/DucTung269/Deep-Learning-Predicting-Creditworthiness/blob/main/images/ANN%20Code.jpg?raw=true)

- Ein **Artificial Neural Network (ANN)** wurde wurde implementiert, das aus einer **Eingabeschicht (Input Layer)**, mehreren **verdeckten Schichten (Hidden Layers)** und einer **Ausgabeschicht (Output Layer)** besteht.  

- Die Eingabeschicht erhält die Eingangsmerkmale des Datensatzes und leitet sie an die verdeckten Schichten weiter. Jede verdeckte Schicht besteht aus einer bestimmten Anzahl von **Neuronen**, die über **lineare Transformationen** (Gewichtungen und Bias) sowie die **ReLU-Aktivierungsfunktion** verarbeitet werden. 

![Hyperparameters](https://github.com/DucTung269/Deep-Learning-Predicting-Creditworthiness/blob/main/images/Hyperparameter.jpg?raw=true)

- Die **Hyperparameter** des neuronalen Netzes konnten flexibel angepasst und wurden anschließend festgelegt, um das Modell zu initialisieren. Dabei wurden die **Eingabegröße**, die **Anzahl der Neuronen pro Schicht**, die **Anzahl der verdeckten Schichten** sowie die **Ausgabegröße** definiert. Das Modell wurde mit einer **Lernrate von 0.0001** trainiert.  

- Als **Verlustfunktion** wurde `BCEWithLogitsLoss` verwendet, wobei ein Gewichtungsfaktor (*pos_weight*) integriert wurde, um das **Klassenungleichgewicht** im Datensatz auszugleichen. Zur Optimierung der Modellparameter kam der **Adam-Optimierer** zum Einsatz.  

- Für den Trainingsprozess wurden **100 Epochen** und eine **Batchgröße von 128** verwendet.  



![outcome](https://github.com/DucTung269/Deep-Learning-Predicting-Creditworthiness/blob/main/images/output.png?raw=true)

- Nach **100 Epochen** konvergiert der **Loss-Wert** auf einen stabilen und niedrigen Wert von etwa **0.20**, was darauf hinweist, dass das Modell die zugrunde liegenden Muster der Daten effektiv erlernt hat. Der **gleichmäßig abfallende Verlauf** des Verlusts über die Epochen hinweg zeigt einen **gut funktionierenden Trainingsprozess**.  

- Es sind **keine Anzeichen von Overfitting** erkennbar, das sich typischerweise durch einen Anstieg des Verlusts auf den Validierungsdaten nach einer bestimmten Anzahl von Epochen äußern würde. Ebenso gibt es **keine Hinweise auf Underfitting**, welches sich durch eine frühe Stagnation des Verlusts auf einem höheren Niveau bemerkbar machen würde.  

![F1](https://github.com/DucTung269/Deep-Learning-Predicting-Creditworthiness/blob/main/images/F1.Score.jpg?raw=true)

- Für den **Trainingsdatensatz** erreichte das Modell eine **Genauigkeit von 77,5 %** und einen **F1-Score von 82,92 %**. Dies zeigt, dass das Modell während der Trainingsphase sowohl in Bezug auf **Präzision** als auch **Sensitivität (Recall)** solide Leistungen erzielte.  

- Beim **Testdatensatz** sank die Genauigkeit leicht auf **75,5 %**, während der **F1-Score mit 80,93 %** weiterhin ein starkes Ergebnis aufweist. Dies deutet darauf hin, dass das Modell seine **Vorhersagefähigkeit auch bei unbekannten Daten beibehalten** konnte, wenngleich mit einem geringfügigen Rückgang der Gesamtgenauigkeit.  

#### Erklärbarkeit der ANN-Modellausgabe mit Shapley Additive Explanations (SHAP) 

![Shap](https://github.com/DucTung269/Deep-Learning-Predicting-Creditworthiness/blob/main/images/ExplainShap.png?raw=true)

Der **SHAP-Summary-Plot** zeigt, welche Merkmale den größten Einfluss auf die Modellvorhersage haben. In der linken Spalte sind alle Merkmale aufgelistet, wobei das **wichtigste Merkmal oben** steht. In diesem Fall stellt **Account_Balance** den stärksten Einflussfaktor dar, gefolgt von der **Length_of_current_employment**, **Value_Savings_Stocks** sowie **Payment_Status_of_Previous_Credit**. Das **Occupation** hat hingegen den geringsten Einfluss auf die Vorhersage.  

Die **x-Achse** stellt die **SHAP-Werte** dar, welche den Einfluss eines Merkmals auf die Modellvorhersage quantifizieren. Jeder Punkt im Diagramm repräsentiert eine Beobachtung im Datensatz und zeigt, ob das entsprechende Merkmal einen **positiven oder negativen Einfluss** auf die Vorhersage hatte.  

Die **Farben der Punkte** geben an, ob das jeweilige Merkmal einen **hohen (rot)** oder **niedrigen (blau)** Wert aufweist.  
- Hohe Kontostände (rote Punkte) erhöhen die Wahrscheinlichkeit einer positiven Kreditentscheidung und wirken sich somit **förderlich auf die Kreditwürdigkeit** aus.  
- Niedrige Kontostände (blaue Punkte) verringern diese Wahrscheinlichkeit und wirken **negativ auf die Kreditwürdigkeit**.  

Ein ähnliches Muster lässt sich bei den Merkmalen **Length_of_current_employment**, **Value_Savings_Stock**, **Payment_Status_of_Previous_Credit** und **Telephone** beobachten. Umgekehrt zeigt sich, dass eine **geringe Anzahl bestehender Kredite bei der gleichen Bank** einen positiven Einfluss hat, während eine hohe Kreditanzahl die Wahrscheinlichkeit einer positiven Bewertung verringert.  

Die **Dichte der Punkte entlang der x-Achse** zeigt, wie häufig bestimmte SHAP-Werte auftreten – eine hohe Dichte bedeutet, dass viele Beobachtungen einen ähnlichen Einfluss des Merkmals auf die Vorhersage aufweisen. Die **vertikale Streuung** eines Merkmals deutet auf eine **starke Wechselwirkung mit anderen Variablen** hin.  

#### Visuelle Erklärbarkeit der ANN-Modellausgabe mit Accumulated Local Effects (ALE)

![ALE](https://github.com/DucTung269/Deep-Learning-Predicting-Creditworthiness/blob/main/images/ExplainALE.png?raw=true)

Die Analyse der **ALE-Plots (Accumulated Local Effects)** ermöglicht ein tieferes Verständnis darüber, welche Merkmale die Vorhersagen des neuronalen Netzes beeinflussen und wie sich diese Effekte über verschiedene Merkmalsausprägungen hinweg verändern. Dadurch wird der **Entscheidungsprozess des Modells** transparenter und nachvollziehbarer.  

In der Abbildung ist zu erkennen, dass **alle Merkmale** Einfluss auf die Vorhersageergebnisse des **ANN-Modells** haben, was sich in den dargestellten **linearen oder nichtlinearen (gekrümmten) Mustern** der ALE-Werte widerspiegelt.  

Zur genaueren Betrachtung werden drei zentrale Merkmale hervorgehoben: **Alter (Age_years)**, **Kontostand (Account_Balance)** und **Kreditbetrag (Credit_Amount)**.  

- Beim Merkmal **Age_years** zeigen die ALE-Werte, dass **jüngere Personen** ein **höheres Risiko eines Kreditausfalls** aufweisen (negative ALE-Werte), während **mittelalte und ältere Personen** ein geringeres Risiko zeigen. Dieses Muster lässt sich durch eine häufig höhere **finanzielle Stabilität im höheren Alter** erklären.  

- Für den **Account_Balance** (Wertebereich 1–4) zeigen die ALE-Werte, dass Personen mit einem **Kontostand größer als 2** ein **deutlich reduziertes Ausfallrisiko** haben. Ein höherer Kontostand steht somit in starkem Zusammenhang mit **finanzieller Zuverlässigkeit**.  

- Beim **Credit_Amount** zeigt sich eine intuitive Beziehung: Mit steigendem Kreditbetrag erhöhen sich auch die ALE-Werte, was auf ein **höheres Ausfallrisiko** hinweist. Größere Kreditsummen bedeuten eine **höhere finanzielle Belastung**, wodurch das Risiko eines Zahlungsausfalls zunimmt.  


#### XGBoost

![XGB](https://github.com/DucTung269/Deep-Learning-Predicting-Creditworthiness/blob/main/images/XGB.jpg?raw=true)

- Das **XGBoost-Modell** wurde für den **Klassifikationsfall** unter Verwendung der gleichen Trainingsdaten wie das **Artificial-Neural-Network-Modell (ANN)** eingesetzt.  

- Die **Leistungsbewertung** des XGBoost-Modells zeigt, dass es ähnlich gute Ergebnisse wie das ANN erzielt hat. Auf dem **Trainingsdatensatz** erreichte das Modell eine **Genauigkeit von 78,3 %** und einen **F1-Score von 79,62 %**. Auf dem **Testdatensatz** wurden eine **Genauigkeit von 73,5 %** und ein **F1-Score von 81 %** erzielt.  

- Diese Ergebnisse deuten darauf hin, dass beide Modelle eine **gute Generalisierungsfähigkeit** aufweisen, wobei sich lediglich **geringfügige Unterschiede in der Vorhersageleistung** zeigen.  

#### Erklärbarkeit der XGBoost-Modellausgabe mit Shapley Additive Explanations (SHAP) 

![SHAP XGB](https://github.com/DucTung269/Deep-Learning-Predicting-Creditworthiness/blob/main/images/SHAP%20for%20XGB.png?raw=true)

- Die Analyse ergab, dass der **Kontostand des Kreditnehmers (Account_Balance)** das **wichtigste Merkmal** im Modell darstellt. Ein höherer Kontostand trägt **positiv zur Vorhersage** bei und signalisiert eine **höhere Wahrscheinlichkeit für Kreditwürdigkeit**, während niedrige Kontostände die Vorhersage deutlich abschwächen.  

- An zweiter und dritter Stelle der wichtigsten Merkmale folgen der **Kreditbetrag (Credit_Amount)** und die **Kreditlaufzeit in Monaten (Duration_of_Credit_monthly)**. Beide Merkmale zeigen eine **inverse Beziehung** zur Modellvorhersage: **niedrigere Werte** sowohl beim Kreditbetrag als auch bei der Kreditlaufzeit wirken sich **positiv auf die Kreditwürdigkeit** aus und erhöhen die Wahrscheinlichkeit einer **günstigen Prognose**.  

- Am unteren Ende der Rangfolge befinden sich die Merkmale **Occupation**, **Foreign_Worker** und **No_of_dependents**. Diese Variablen zeigen nur einen **geringen Einfluss auf die Modellvorhersage**, was darauf hinweist, dass sie zwar im Modell enthalten sind, ihr Beitrag zum **Gesamtentscheidungsprozess** jedoch im Vergleich zu den übrigen Merkmalen **vernachlässigbar** ist.  


#### Visuelle Erklärbarkeit der XGBoost-Modellausgabe mit Accumulated Local Effects (ALE)

![ALE XGB](https://github.com/DucTung269/Deep-Learning-Predicting-Creditworthiness/blob/main/images/ALE%20for%20XGB.png?raw=true)

- In der Abbildung zeigen die Merkmale **No_of_dependents**, **Type_of_apartment**, **Foreign_Workers** und **Occupation** nur einen **geringen oder keinen erkennbaren Einfluss** auf die Modellvorhersage. Ihre **ALE-Werte bleiben über alle Merkmalsausprägungen hinweg nahezu konstant**, was darauf hindeutet, dass diese Variablen **keinen signifikanten Beitrag** zu den Entscheidungen des Modells leisten.  

- Die **ALE-Plots des XGBoost-Modells** zeigen, dass die drei Merkmale **Alter (Age_years)**, **Kontostand (Account_Balance)** und **Kreditbetrag (Credit_Amount)** ähnliche Ergebnisse liefern wie beim **ANN-Modell**.  

- Allerdings lässt sich beim Merkmal **Age_years** ein leichter Unterschied erkennen: **Personen mittleren Alters** weisen laut den ALE-Werten eine **etwas höhere Wahrscheinlichkeit auf, einen Kredit aufzunehmen**, als ältere Personen.  

- Beim **Account_Balance** bleibt der Trend konsistent: Individuen mit einem **Kontostand größer als 2** zeigen ein **deutlich geringeres Ausfallrisiko**, was erneut die enge **Korrelation zwischen höherem Kontostand und finanzieller Stabilität** bestätigt.  

- Ebenso zeigt das Merkmal **Credit_Amount**, dass **höhere Kreditsummen mit einem erhöhten Risiko eines Zahlungsausfalls** einhergehen — ein Ergebnis, das den allgemeinen wirtschaftlichen Erwartungen entspricht.  

---

### Fazit  

In dieser Studie wurde der Einsatz von **Künstlichen Neuronalen Netzen (Artificial Neural Networks, ANN)** und **XGBoost** zur **Vorhersage der Kreditwürdigkeit** untersucht, wobei der Schwerpunkt auf dem Vergleich ihrer **Leistungsfähigkeit und Interpretierbarkeit** lag.  

Unter Anwendung moderner **Machine-Learning-Methoden** wurde der **German Credit Dataset** analysiert, die Daten wurden vorverarbeitet und die Modellparameter optimiert, um **präzise und verlässliche Vorhersagen** zu erzielen. Beide Modelle – ANN und XGBoost – zeigten anhand von Leistungskennzahlen wie **Genauigkeit (Accuracy)** und **F1-Score** eine vergleichbare Performance, was ihre **Eignung für die Bewertung von Kreditrisiken** bestätigt.  

Neben der Leistungsbewertung lag ein besonderer Fokus auf der **Erklärbarkeit der Modelle**, um deren Black-Box-Charakter zu reduzieren. Hierfür wurden die **SHAP (Shapley Additive Explanations)**- und **ALE (Accumulated Local Effects)**-Methoden eingesetzt, um **Einblicke in die Merkmalsbedeutung und die Entscheidungsprozesse** der Modelle zu gewinnen. Während SHAP sowohl **globale als auch lokale Erklärungen** ermöglicht, bietet ALE eine **rechenökonomische Methode** zur Analyse der Merkmalseffekte und trägt somit zu einer **transparenten und nachvollziehbaren Modellbewertung** bei.  

Die Ergebnisse dieser Arbeit unterstreichen die **Bedeutung der Integration von Erklärbarkeitsansätzen** in KI-gestützte Entscheidungsprozesse im Finanzwesen, um **Vertrauen, Nachvollziehbarkeit und regulatorische Konformität** zu fördern.  
